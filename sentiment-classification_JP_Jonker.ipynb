{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries that will be used in this predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:16.187380Z",
     "iopub.status.busy": "2022-10-11T14:12:16.186821Z",
     "iopub.status.idle": "2022-10-11T14:12:17.503395Z",
     "shell.execute_reply": "2022-10-11T14:12:17.501750Z",
     "shell.execute_reply.started": "2022-10-11T14:12:16.187298Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\jeanj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Libaries to process data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Libaries for visualization\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#import libraries to preprocess/clean twitter data\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "#import word cleaning and reformatting libraries\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#import feature extraction libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#import train test split library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import feature standarization library\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#import feature selection libraries\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "#import all classifier models that will be used\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "#import libraries used for metrics of models\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#import hyper paramerter tuning libraries using cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "#Save model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:17.506586Z",
     "iopub.status.busy": "2022-10-11T14:12:17.506072Z",
     "iopub.status.idle": "2022-10-11T14:12:17.614315Z",
     "shell.execute_reply": "2022-10-11T14:12:17.612824Z",
     "shell.execute_reply.started": "2022-10-11T14:12:17.506544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15819, 3)\n",
      "(10546, 2)\n"
     ]
    }
   ],
   "source": [
    "#import training and testing data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "#print shape of training and testing data\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:17.618476Z",
     "iopub.status.busy": "2022-10-11T14:12:17.618012Z",
     "iopub.status.idle": "2022-10-11T14:12:17.631757Z",
     "shell.execute_reply": "2022-10-11T14:12:17.630728Z",
     "shell.execute_reply.started": "2022-10-11T14:12:17.618437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "   sentiment                                            message  tweetid\n",
      "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
      "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
      "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
      "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
      "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954\n",
      "\n",
      "Test data\n",
      "                                             message  tweetid\n",
      "0  Europe will now be looking to China to make su...   169760\n",
      "1  Combine this with the polling of staffers re c...    35326\n",
      "2  The scary, unimpeachable evidence that climate...   224985\n",
      "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
      "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928\n"
     ]
    }
   ],
   "source": [
    "#Display the header of training and testing data\n",
    "print(\"Train data\")\n",
    "print(train_df.head())\n",
    "print(\"\\nTest data\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:17.634534Z",
     "iopub.status.busy": "2022-10-11T14:12:17.633102Z",
     "iopub.status.idle": "2022-10-11T14:12:17.656247Z",
     "shell.execute_reply": "2022-10-11T14:12:17.654718Z",
     "shell.execute_reply.started": "2022-10-11T14:12:17.634318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "   tweetid                                            message  sentiment\n",
      "0   625221  PolySciMajor EPA chief doesn't think carbon di...          1\n",
      "1   126103  It's not like we lack evidence of anthropogeni...          1\n",
      "2   698562  RT @RawStory: Researchers say we have three ye...          2\n",
      "3   573736  #TodayinMaker# WIRED : 2016 was a pivotal year...          1\n",
      "4   466954  RT @SoyNovioDeTodas: It's 2016, and a racist, ...          1\n",
      "\n",
      "Test data\n",
      "   tweetid                                            message\n",
      "0   169760  Europe will now be looking to China to make su...\n",
      "1    35326  Combine this with the polling of staffers re c...\n",
      "2   224985  The scary, unimpeachable evidence that climate...\n",
      "3   476263  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...\n",
      "4   872928  RT @FakeWillMoore: 'Female orgasms cause globa...\n"
     ]
    }
   ],
   "source": [
    "#Reformat the dataframe view for training and testing data\n",
    "train_df = train_df[['tweetid','message','sentiment']]\n",
    "test_df = test_df[['tweetid','message']]\n",
    "#Display the header of training and testing data\n",
    "print(\"Train data\")\n",
    "print(train_df.head())\n",
    "print(\"\\nTest data\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data cleaning and preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:17.658380Z",
     "iopub.status.busy": "2022-10-11T14:12:17.657815Z",
     "iopub.status.idle": "2022-10-11T14:12:17.669992Z",
     "shell.execute_reply": "2022-10-11T14:12:17.668874Z",
     "shell.execute_reply.started": "2022-10-11T14:12:17.658330Z"
    }
   },
   "outputs": [],
   "source": [
    "#Combine the training and testing data for data cleaning and preprocessing\n",
    "df = pd.concat([train_df, test_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:17.672799Z",
     "iopub.status.busy": "2022-10-11T14:12:17.671643Z",
     "iopub.status.idle": "2022-10-11T14:12:17.711847Z",
     "shell.execute_reply": "2022-10-11T14:12:17.710663Z",
     "shell.execute_reply.started": "2022-10-11T14:12:17.672753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tweetid</th>\n",
       "      <td>26365.0</td>\n",
       "      <td>499791.634971</td>\n",
       "      <td>288678.408660</td>\n",
       "      <td>6.0</td>\n",
       "      <td>249928.0</td>\n",
       "      <td>499577.0</td>\n",
       "      <td>748695.0</td>\n",
       "      <td>999983.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>15819.0</td>\n",
       "      <td>0.917504</td>\n",
       "      <td>0.836537</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count           mean            std  min       25%       50%  \\\n",
       "tweetid    26365.0  499791.634971  288678.408660  6.0  249928.0  499577.0   \n",
       "sentiment  15819.0       0.917504       0.836537 -1.0       1.0       1.0   \n",
       "\n",
       "                75%       max  \n",
       "tweetid    748695.0  999983.0  \n",
       "sentiment       1.0       2.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show descriptive statistics information for the dataframe\n",
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:17.714115Z",
     "iopub.status.busy": "2022-10-11T14:12:17.713489Z",
     "iopub.status.idle": "2022-10-11T14:12:17.729195Z",
     "shell.execute_reply": "2022-10-11T14:12:17.727714Z",
     "shell.execute_reply.started": "2022-10-11T14:12:17.714080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweetid          0\n",
       "message          0\n",
       "sentiment    10546\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if data have any blank values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:17.732426Z",
     "iopub.status.busy": "2022-10-11T14:12:17.730878Z",
     "iopub.status.idle": "2022-10-11T14:12:17.858663Z",
     "shell.execute_reply": "2022-10-11T14:12:17.857374Z",
     "shell.execute_reply.started": "2022-10-11T14:12:17.732336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>625221</td>\n",
       "      <td>polyscimajor epa chief doesn't think carbon di...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126103</td>\n",
       "      <td>it's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>698562</td>\n",
       "      <td>rt @rawstory: researchers say we have three ye...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>573736</td>\n",
       "      <td>#todayinmaker# wired : 2016 was a pivotal year...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>466954</td>\n",
       "      <td>rt @soynoviodetodas: it's 2016, and a racist, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>895714</td>\n",
       "      <td>rt @brittanybohrer: brb, writing a poem about ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>875167</td>\n",
       "      <td>2016: the year climate change came home: durin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>78329</td>\n",
       "      <td>rt @loop_vanuatu: pacific countries positive a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10544</th>\n",
       "      <td>867455</td>\n",
       "      <td>rt @xanria_00018: you’re so hot, you must be t...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10545</th>\n",
       "      <td>470892</td>\n",
       "      <td>rt @chloebalaoing: climate change is a global ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26365 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweetid                                            message  sentiment\n",
       "0       625221  polyscimajor epa chief doesn't think carbon di...        1.0\n",
       "1       126103  it's not like we lack evidence of anthropogeni...        1.0\n",
       "2       698562  rt @rawstory: researchers say we have three ye...        2.0\n",
       "3       573736  #todayinmaker# wired : 2016 was a pivotal year...        1.0\n",
       "4       466954  rt @soynoviodetodas: it's 2016, and a racist, ...        1.0\n",
       "...        ...                                                ...        ...\n",
       "10541   895714  rt @brittanybohrer: brb, writing a poem about ...        NaN\n",
       "10542   875167  2016: the year climate change came home: durin...        NaN\n",
       "10543    78329  rt @loop_vanuatu: pacific countries positive a...        NaN\n",
       "10544   867455  rt @xanria_00018: you’re so hot, you must be t...        NaN\n",
       "10545   470892  rt @chloebalaoing: climate change is a global ...        NaN\n",
       "\n",
       "[26365 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove all of the urls from message column\n",
    "def remove_urls_lower(df_to_clean):\n",
    "    #identify url pattern\n",
    "    url_pattern = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "    #new string for url\n",
    "    url = r'urlweb'\n",
    "    #replace with string\n",
    "    df_to_clean['message'] = df_to_clean['message'].replace(to_replace=url_pattern, value=url,regex=True)\n",
    "    df_to_clean['message'] = df_to_clean['message'].str.lower()\n",
    "    return df_to_clean\n",
    "\n",
    "#insert df and return df with urls removed\n",
    "remove_urls_lower(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:17.861213Z",
     "iopub.status.busy": "2022-10-11T14:12:17.860584Z",
     "iopub.status.idle": "2022-10-11T14:12:18.225299Z",
     "shell.execute_reply": "2022-10-11T14:12:18.224397Z",
     "shell.execute_reply.started": "2022-10-11T14:12:17.861160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        polyscimajor epa chief doesnt think carbon dio...\n",
       "1        its not like we lack evidence of anthropogenic...\n",
       "2        rt rawstory researchers say we have three year...\n",
       "3        todayinmaker wired   was a pivotal year in the...\n",
       "4        rt soynoviodetodas its  and a racist sexist cl...\n",
       "                               ...                        \n",
       "10541    rt brittanybohrer brb writing a poem about cli...\n",
       "10542     the year climate change came home during the ...\n",
       "10543    rt loopvanuatu pacific countries positive abou...\n",
       "10544    rt xanria youre so hot you must be the cause f...\n",
       "10545    rt chloebalaoing climate change is a global is...\n",
       "Name: message, Length: 26365, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove all punctuation, numbers and special characters from message column\n",
    "def remove_punctuation(message):\n",
    "    punctuation = string.punctuation\n",
    "    numbers = '0123456789'\n",
    "    special_char = 'â€¦\",\"ðŸ¥³ã¢‚¬.ï¿½'\n",
    "    remove_char = punctuation+numbers+special_char\n",
    "    cleaned_sentence = ''.join([char for char in message if char not in remove_char])\n",
    "    #Remove unicode characters\n",
    "    encode = cleaned_sentence.encode('ascii', 'ignore')\n",
    "    decode_cleaned_sentence = encode.decode()\n",
    "    return decode_cleaned_sentence\n",
    "\n",
    "#apply remove _punctuation function on message column of whole dataframe\n",
    "df['message'] =df['message'].apply(remove_punctuation)\n",
    "df['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:18.227266Z",
     "iopub.status.busy": "2022-10-11T14:12:18.226576Z",
     "iopub.status.idle": "2022-10-11T14:12:22.682895Z",
     "shell.execute_reply": "2022-10-11T14:12:22.681191Z",
     "shell.execute_reply.started": "2022-10-11T14:12:18.227227Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create instance of Lemmatizer\n",
    "lemmatized = WordNetLemmatizer()\n",
    "#Create funtion to split, lemmatise and combine a sentence\n",
    "def lemma_df(sentence, lemmatized):\n",
    "    spliting = sentence.split(' ')\n",
    "    lemmatized_sentence = [lemmatized.lemmatize(word) for word in spliting]\n",
    "    combine_words = ' '.join(lemmatized_sentence)\n",
    "    return combine_words\n",
    "#apply lemma_df function on message column of whole dataframe\n",
    "df['message'] = df['message'].apply(lemma_df, args=(lemmatized,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split cleaned data into training and testing datasets\n",
    "training_data = df[pd.notnull(df['sentiment'])]\n",
    "testing_data = df[pd.isnull(df['sentiment'])].drop(['sentiment'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:22.685317Z",
     "iopub.status.busy": "2022-10-11T14:12:22.684916Z",
     "iopub.status.idle": "2022-10-11T14:12:23.767960Z",
     "shell.execute_reply": "2022-10-11T14:12:23.766706Z",
     "shell.execute_reply.started": "2022-10-11T14:12:22.685280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeanj\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#create variable to store all of the english stopwords\n",
    "stopwords_list = stopwords.words('english')\n",
    "#create instance of countvectoriser\n",
    "vect = CountVectorizer(stop_words=stopwords_list, ngram_range=(1,2), max_df=0.1, min_df=3)\n",
    "#fit data to countvectoriser instance\n",
    "X = vect.fit_transform(training_data['message'])\n",
    "#display number of features selected\n",
    "print(len(vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:23.774670Z",
     "iopub.status.busy": "2022-10-11T14:12:23.773836Z",
     "iopub.status.idle": "2022-10-11T14:12:24.651318Z",
     "shell.execute_reply": "2022-10-11T14:12:24.649976Z",
     "shell.execute_reply.started": "2022-10-11T14:12:23.774618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15819"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm lenght of training data\n",
    "len(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:24.653529Z",
     "iopub.status.busy": "2022-10-11T14:12:24.653108Z",
     "iopub.status.idle": "2022-10-11T14:12:25.044854Z",
     "shell.execute_reply": "2022-10-11T14:12:25.043441Z",
     "shell.execute_reply.started": "2022-10-11T14:12:24.653493Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create new dataframe with the vectorised training data\n",
    "training_data_vectorised = pd.DataFrame(X.toarray(), columns=vect.get_feature_names())\n",
    "training_data_vectorised['tweetid'] = training_data['tweetid'].values\n",
    "training_data_vectorised['sentiment'] = training_data['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:25.048414Z",
     "iopub.status.busy": "2022-10-11T14:12:25.047853Z",
     "iopub.status.idle": "2022-10-11T14:12:25.054825Z",
     "shell.execute_reply": "2022-10-11T14:12:25.053827Z",
     "shell.execute_reply.started": "2022-10-11T14:12:25.048336Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove previous unused dataframes to lower memory usage\n",
    "del train_df\n",
    "del test_df\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10546, 13289)\n"
     ]
    }
   ],
   "source": [
    "#vectorise the testing data\n",
    "Xtesting = vect.transform(testing_data['message'])\n",
    "#confirm shape of vectorised testing data\n",
    "print(Xtesting.shape)\n",
    "#Create new dataframe with the vectorised testing data\n",
    "testing_data_vectorised = pd.DataFrame(Xtesting.toarray(), columns=vect.get_feature_names())\n",
    "testing_data_vectorised['tweetid'] = testing_data['tweetid'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15819, 13291)\n",
      "(10546, 13290)\n"
     ]
    }
   ],
   "source": [
    "#print shapes of testing and training dataframes\n",
    "print(training_data_vectorised.shape)\n",
    "print(testing_data_vectorised.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:25.056899Z",
     "iopub.status.busy": "2022-10-11T14:12:25.056148Z",
     "iopub.status.idle": "2022-10-11T14:12:27.510277Z",
     "shell.execute_reply": "2022-10-11T14:12:27.508846Z",
     "shell.execute_reply.started": "2022-10-11T14:12:25.056853Z"
    }
   },
   "outputs": [],
   "source": [
    "#change classes to integer\n",
    "training_data_vectorised['sentiment'] = training_data_vectorised['sentiment'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:27.522385Z",
     "iopub.status.busy": "2022-10-11T14:12:27.521882Z",
     "iopub.status.idle": "2022-10-11T14:12:27.550337Z",
     "shell.execute_reply": "2022-10-11T14:12:27.549007Z",
     "shell.execute_reply.started": "2022-10-11T14:12:27.522315Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove previous unused dataframes to lower memory usage\n",
    "del vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:27.582298Z",
     "iopub.status.busy": "2022-10-11T14:12:27.581826Z",
     "iopub.status.idle": "2022-10-11T14:12:27.606886Z",
     "shell.execute_reply": "2022-10-11T14:12:27.605834Z",
     "shell.execute_reply.started": "2022-10-11T14:12:27.582258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandoning climate</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abc</th>\n",
       "      <th>abc john</th>\n",
       "      <th>abc news</th>\n",
       "      <th>...</th>\n",
       "      <th>zealot</th>\n",
       "      <th>zero</th>\n",
       "      <th>zero question</th>\n",
       "      <th>zeroco</th>\n",
       "      <th>zika</th>\n",
       "      <th>zinke</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone urlweb</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaa  ab  abandon  abandoned  abandoning  abandoning climate  abbott  abc  \\\n",
       "0    0   0        0          0           0                   0       0    0   \n",
       "1    0   0        0          0           0                   0       0    0   \n",
       "2    0   0        0          0           0                   0       0    0   \n",
       "3    0   0        0          0           0                   0       0    0   \n",
       "4    0   0        0          0           0                   0       0    0   \n",
       "\n",
       "   abc john  abc news  ...  zealot  zero  zero question  zeroco  zika  zinke  \\\n",
       "0         0         0  ...       0     0              0       0     0      0   \n",
       "1         0         0  ...       0     0              0       0     0      0   \n",
       "2         0         0  ...       0     0              0       1     0      0   \n",
       "3         0         0  ...       0     0              0       0     0      0   \n",
       "4         0         0  ...       0     0              0       0     0      0   \n",
       "\n",
       "   zoe  zone  zone urlweb  tweetid  \n",
       "0    0     0            0   169760  \n",
       "1    0     0            0    35326  \n",
       "2    0     0            0   224985  \n",
       "3    0     0            0   476263  \n",
       "4    0     0            0   872928  \n",
       "\n",
       "[5 rows x 13290 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display vectorised testing dataframe header\n",
    "testing_data_vectorised.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:27.609084Z",
     "iopub.status.busy": "2022-10-11T14:12:27.608716Z",
     "iopub.status.idle": "2022-10-11T14:12:27.625695Z",
     "shell.execute_reply": "2022-10-11T14:12:27.624191Z",
     "shell.execute_reply.started": "2022-10-11T14:12:27.609052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    8530\n",
       " 2    3640\n",
       " 0    2353\n",
       "-1    1296\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#determine observations per response/class \n",
    "counting = training_data_vectorised['sentiment'].value_counts()\n",
    "counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:27.627826Z",
     "iopub.status.busy": "2022-10-11T14:12:27.627293Z",
     "iopub.status.idle": "2022-10-11T14:12:27.866638Z",
     "shell.execute_reply": "2022-10-11T14:12:27.865142Z",
     "shell.execute_reply.started": "2022-10-11T14:12:27.627776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x21da36c3940>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display observations per response/class\n",
    "plt.bar(counting.index.astype(str),counting.values)\n",
    "plt.hlines(y=8530, xmin=0,xmax=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:27.880335Z",
     "iopub.status.busy": "2022-10-11T14:12:27.879903Z",
     "iopub.status.idle": "2022-10-11T14:12:27.894754Z",
     "shell.execute_reply": "2022-10-11T14:12:27.893342Z",
     "shell.execute_reply.started": "2022-10-11T14:12:27.880266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    8530\n",
       " 2    3640\n",
       " 0    2353\n",
       "-1    1296\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print out amount per class\n",
    "counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandoning climate</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abc</th>\n",
       "      <th>abc john</th>\n",
       "      <th>abc news</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zero question</th>\n",
       "      <th>zeroco</th>\n",
       "      <th>zika</th>\n",
       "      <th>zinke</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone urlweb</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>625221</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>698562</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>573736</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>466954</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15814</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15815</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17856</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15816</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>384248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15817</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>819732</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15818</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>806319</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15819 rows × 13291 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aaa  ab  abandon  abandoned  abandoning  abandoning climate  abbott  \\\n",
       "0        0   0        0          0           0                   0       0   \n",
       "1        0   0        0          0           0                   0       0   \n",
       "2        0   0        0          0           0                   0       0   \n",
       "3        0   0        0          0           0                   0       0   \n",
       "4        0   0        0          0           0                   0       0   \n",
       "...    ...  ..      ...        ...         ...                 ...     ...   \n",
       "15814    0   0        0          0           0                   0       0   \n",
       "15815    0   0        0          0           0                   0       0   \n",
       "15816    0   0        0          0           0                   0       0   \n",
       "15817    0   0        0          0           0                   0       0   \n",
       "15818    0   0        0          0           0                   0       0   \n",
       "\n",
       "       abc  abc john  abc news  ...  zero  zero question  zeroco  zika  zinke  \\\n",
       "0        0         0         0  ...     0              0       0     0      0   \n",
       "1        0         0         0  ...     0              0       0     0      0   \n",
       "2        0         0         0  ...     0              0       0     0      0   \n",
       "3        0         0         0  ...     0              0       0     0      0   \n",
       "4        0         0         0  ...     0              0       0     0      0   \n",
       "...    ...       ...       ...  ...   ...            ...     ...   ...    ...   \n",
       "15814    0         0         0  ...     0              0       0     0      0   \n",
       "15815    0         0         0  ...     0              0       0     0      0   \n",
       "15816    0         0         0  ...     0              0       0     0      0   \n",
       "15817    0         0         0  ...     0              0       0     0      0   \n",
       "15818    0         0         0  ...     0              0       0     0      0   \n",
       "\n",
       "       zoe  zone  zone urlweb  tweetid  sentiment  \n",
       "0        0     0            0   625221          1  \n",
       "1        0     0            0   126103          1  \n",
       "2        0     0            0   698562          2  \n",
       "3        0     0            0   573736          1  \n",
       "4        0     0            0   466954          1  \n",
       "...    ...   ...          ...      ...        ...  \n",
       "15814    0     0            0    22001          1  \n",
       "15815    0     0            0    17856          2  \n",
       "15816    0     0            0   384248          0  \n",
       "15817    0     0            0   819732         -1  \n",
       "15818    0     0            0   806319          0  \n",
       "\n",
       "[15819 rows x 13291 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display training \n",
    "training_data_vectorised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:27.896862Z",
     "iopub.status.busy": "2022-10-11T14:12:27.896461Z",
     "iopub.status.idle": "2022-10-11T14:12:28.612967Z",
     "shell.execute_reply": "2022-10-11T14:12:28.611629Z",
     "shell.execute_reply.started": "2022-10-11T14:12:27.896827Z"
    }
   },
   "outputs": [],
   "source": [
    "#create individual training data for each response\n",
    "response_1 = training_data_vectorised[training_data_vectorised['sentiment']==1]\n",
    "response_2 = training_data_vectorised[training_data_vectorised['sentiment']==2]\n",
    "response_0 = training_data_vectorised[training_data_vectorised['sentiment']==0]\n",
    "response_neg_1 = training_data_vectorised[training_data_vectorised['sentiment']==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:28.617874Z",
     "iopub.status.busy": "2022-10-11T14:12:28.617436Z",
     "iopub.status.idle": "2022-10-11T14:12:28.624875Z",
     "shell.execute_reply": "2022-10-11T14:12:28.622824Z",
     "shell.execute_reply.started": "2022-10-11T14:12:28.617835Z"
    }
   },
   "outputs": [],
   "source": [
    "#use the max observation class to upsample all data\n",
    "middle_response = 8530"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:28.627738Z",
     "iopub.status.busy": "2022-10-11T14:12:28.627170Z",
     "iopub.status.idle": "2022-10-11T14:12:29.931678Z",
     "shell.execute_reply": "2022-10-11T14:12:29.930418Z",
     "shell.execute_reply.started": "2022-10-11T14:12:28.627684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 4 artists>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#resmaple the different class dataframes\n",
    "response_1_downsample = resample(response_1, replace=False, n_samples= middle_response, random_state=42)\n",
    "response_2_upsample = resample(response_2, replace=True, n_samples= middle_response, random_state=42)\n",
    "response_0_upsample = resample(response_0, replace=True, n_samples= middle_response, random_state=42)\n",
    "response_neg_1_upsample = resample(response_neg_1, replace=True, n_samples= middle_response, random_state=42)\n",
    "#combined the resample datframes\n",
    "train_resampled = pd.concat([response_1_downsample,response_2_upsample,response_0_upsample,response_neg_1_upsample], axis=0)\n",
    "#display resamle class amount of observations\n",
    "plt.bar(train_resampled['sentiment'].value_counts().index.astype(str),train_resampled['sentiment'].value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:45.460213Z",
     "iopub.status.busy": "2022-10-11T14:12:45.459241Z",
     "iopub.status.idle": "2022-10-11T14:12:45.473375Z",
     "shell.execute_reply": "2022-10-11T14:12:45.472218Z",
     "shell.execute_reply.started": "2022-10-11T14:12:45.460150Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove previous unused dataframes to lower memory usage\n",
    "del response_1\n",
    "del response_2\n",
    "del response_0\n",
    "del response_neg_1\n",
    "del response_1_downsample\n",
    "del response_2_upsample\n",
    "del response_0_upsample\n",
    "del response_neg_1_upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:46.143679Z",
     "iopub.status.busy": "2022-10-11T14:12:46.143199Z",
     "iopub.status.idle": "2022-10-11T14:12:46.475669Z",
     "shell.execute_reply": "2022-10-11T14:12:46.474429Z",
     "shell.execute_reply.started": "2022-10-11T14:12:46.143632Z"
    }
   },
   "outputs": [],
   "source": [
    "#use the train dataset and define the feature and response data\n",
    "X = train_resampled.drop(['tweetid','sentiment'], axis=1)\n",
    "Y = train_resampled['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:12:49.622583Z",
     "iopub.status.busy": "2022-10-11T14:12:49.621677Z",
     "iopub.status.idle": "2022-10-11T14:12:51.295627Z",
     "shell.execute_reply": "2022-10-11T14:12:51.294316Z",
     "shell.execute_reply.started": "2022-10-11T14:12:49.622543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34120, 9297)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#implement feature selection for vectorised data\n",
    "threshold = VarianceThreshold(threshold=0.0002)\n",
    "X_threshold_scaled_data = threshold.fit_transform(X)\n",
    "#confirm shape of threshold\n",
    "X_threshold_scaled_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeanj\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jeanj\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jeanj\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeC\n",
      "Model: RandomForestC\n"
     ]
    }
   ],
   "source": [
    "#Create a list of all model instances\n",
    "models = [LogisticRegression()\n",
    "          ,DecisionTreeClassifier()\n",
    "          ,RandomForestClassifier()\n",
    "          ,SVC(max_iter=50)\n",
    "          ,GaussianNB()\n",
    "          ,KNeighborsClassifier()\n",
    "          ,AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "          ,MLPClassifier()\n",
    "          ,XGBClassifier()\n",
    "          ,LGBMClassifier()\n",
    "          ,OneVsRestClassifier(SVC(max_iter=50))]\n",
    "\n",
    "#empty result list to save results\n",
    "result = []\n",
    "#Create a list of all model names\n",
    "model_names = ['LR','DecisionTreeC','RandomForestC','SVC','naive_bayes','KNN',\n",
    "'AdaBoostC','MLPC','XGBoost','lgbm_model','OneVsRestClassifier']\n",
    "\n",
    "#Create a tuple for each model name and instance and complete and used cross validation to measure model\n",
    "for name, model in zip(model_names, models):\n",
    "    if name == 'XGBoost':\n",
    "        print(fr\"Model: {name}\")\n",
    "        scores = cross_val_score(model, X_threshold_scaled_data, Y+1, cv=3, scoring= make_scorer(metrics.f1_score, average='macro'))\n",
    "        mean_f1_score_score = scores.mean()\n",
    "        std_score_score = scores.std()\n",
    "        result.append([name, mean_f1_score_score, std_score_score])\n",
    "    else:\n",
    "        print(fr\"Model: {name}\")\n",
    "        scores = cross_val_score(model, X_threshold_scaled_data, Y, cv=3, scoring= make_scorer(metrics.f1_score, average='macro'))\n",
    "        mean_f1_score_score = scores.mean()\n",
    "        std_score_score = scores.std()\n",
    "        result.append([name, mean_f1_score_score, std_score_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show result from cross validation\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add results to a dataframe\n",
    "results_df = pd.DataFrame(result, columns=[name, mean_f1_score_score, std_score_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results to an excel file\n",
    "results_df.to_excel('results_notebook_without standard th002.xlsx')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate_grid function will be used to calculate results from gridsearch using different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:13:33.714986Z",
     "iopub.status.busy": "2022-10-11T14:13:33.714456Z",
     "iopub.status.idle": "2022-10-11T14:13:33.726461Z",
     "shell.execute_reply": "2022-10-11T14:13:33.724173Z",
     "shell.execute_reply.started": "2022-10-11T14:13:33.714934Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_grid(estimator_used, parameters_chosen):\n",
    "    #Use gridsearch to calculate Macro f1 score\n",
    "    gridsearch = GridSearchCV(estimator=estimator_used, param_grid= parameters_chosen,scoring = make_scorer(metrics.f1_score, average='macro'), cv = 3, return_train_score=True)\n",
    "    gridsearch.fit(X_threshold_scaled_data,Y)\n",
    "    #Add results to dataframe and save to excel\n",
    "    grid_results = pd.DataFrame(gridsearch.cv_results_)\n",
    "    grid_results.to_excel('grid results.xlsx', index=False)\n",
    "    #save mean and standard dev train and test scores\n",
    "    view_mean = grid_results[['mean_train_score', 'mean_test_score','std_train_score', 'std_test_score']]\n",
    "    #display best parameters\n",
    "    print(f'\\n{gridsearch.best_params_}')\n",
    "    #print mean and standard dev train and test scores\n",
    "    print(view_mean)\n",
    "    #print mean train and test scores\n",
    "    plt.plot(view_mean['mean_train_score'])\n",
    "    plt.plot(view_mean['mean_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print vectorised testing data\n",
    "testing_data_vectorised.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:13:33.731744Z",
     "iopub.status.busy": "2022-10-11T14:13:33.730582Z",
     "iopub.status.idle": "2022-10-11T14:13:34.263637Z",
     "shell.execute_reply": "2022-10-11T14:13:34.262063Z",
     "shell.execute_reply.started": "2022-10-11T14:13:33.731686Z"
    }
   },
   "outputs": [],
   "source": [
    "#preprocess all testing data\n",
    "print(\"Creating testing data\")\n",
    "#remove tweetid from testing data\n",
    "X_testing_data = testing_data_vectorised.drop(['tweetid'], axis=1)\n",
    "#feature selection transform testing data\n",
    "X_testing_data =  threshold.transform(X_testing_data)\n",
    "#confirm shape of testing data preprocessed\n",
    "print(X_testing_data.shape)\n",
    "X_testing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iteration used to create unique values for parameter grid\n",
    "iteration = [int(round(i,0)) for i in np.linspace(300, 550, 50)]\n",
    "#identify parameters to test\n",
    "parameter_grid = {'criterion': ['entropy'], 'min_samples_split' :[2], 'min_samples_leaf':[1], 'max_features' : ['auto'], \n",
    "                  'min_impurity_decrease':[0.0], 'ccp_alpha':[0.0]}\n",
    "#calculate best parameters\n",
    "calculate_grid(DecisionTreeClassifier(),parameter_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test decison tree on adjusted parameters\n",
    "dt_clf =  DecisionTreeClassifier(ccp_alpha= 0.0, criterion= 'entropy', max_features= 'auto', min_impurity_decrease= 0.0, min_samples_leaf= 1, min_samples_split= 2, random_state=42)\n",
    "dt_clf.fit(X_threshold_scaled_data,Y)\n",
    "y_pred = dt_clf.predict(X_testing_data)\n",
    "#Convert results to dataframe and save as csv\n",
    "result_testing = testing_data.copy()\n",
    "result_testing['sentiment'] = y_pred\n",
    "result_testing = result_testing[['tweetid','sentiment']]\n",
    "result_testing.to_csv('dt_clf.csv', index=False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest non standardised data and threshold of 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iteration used to create unique values for parameter grid\n",
    "iteration = [int(round(i,0)) for i in np.linspace(100, 200, 10)]\n",
    "#define parameters\n",
    "parameter_grid = {'n_estimators' : [100], 'criterion': ['entropy']}\n",
    "#calculate best parameters\n",
    "calculate_grid(RandomForestClassifier(), parameter_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test random forest on adjusted parameters\n",
    "rf_clf =  RandomForestClassifier(n_estimators= 100 ,criterion= 'entropy', random_state=42)\n",
    "rf_clf.fit(X_threshold_scaled_data,Y)\n",
    "y_pred = rf_clf.predict(X_testing_data)\n",
    "y_pred\n",
    "#Convert results to dataframe and save as csv\n",
    "result_testing = testing_data.copy()\n",
    "result_testing['sentiment'] = y_pred\n",
    "result_testing = result_testing[['tweetid','sentiment']]\n",
    "result_testing.to_csv('rf_clf.csv', index=False)\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:13:34.269213Z",
     "iopub.status.busy": "2022-10-11T14:13:34.267718Z"
    }
   },
   "outputs": [],
   "source": [
    "#define parameters\n",
    "parameter_grid = {\n",
    "    'hidden_layer_sizes': [(300,200,100)], \n",
    "    'max_iter': [100],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam'], \n",
    "    'alpha': [0.001],\n",
    "    'learning_rate': ['adaptive']}\n",
    "#calculate best parameters\n",
    "calculate_grid(MLPClassifier(), parameter_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test MLP on adjusted parameters\n",
    "MLP_clf =  MLPClassifier(\n",
    "    hidden_layer_sizes = (300,200,100), \n",
    "    max_iter= 100,\n",
    "    activation= 'relu',\n",
    "    solver= 'adam', \n",
    "    alpha= 0.001,\n",
    "    learning_rate= 'adaptive', random_state=42)\n",
    "#Convert results to dataframe and save as csv\n",
    "MLP_clf.fit(X_threshold_scaled_data,Y)\n",
    "y_pred = MLP_clf.predict(X_testing_data)\n",
    "y_pred\n",
    "\n",
    "result_testing = testing_data.copy()\n",
    "result_testing['sentiment'] = y_pred\n",
    "result_testing = result_testing[['tweetid','sentiment']]\n",
    "result_testing.to_csv('MLP_clf.csv', index=False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow and keras to use neural network model\n",
    "import tensorflow as tf\n",
    "#import dense and sequential libraries for model layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "#reformat y train for model\n",
    "Y_nn = train_resampled['sentiment'] + 1\n",
    "#change shape of training and testing data\n",
    "X_threshold_scaled_data_reshaped = np.array(X_threshold_scaled_data).reshape(-1,X_threshold_scaled_data.shape[1])\n",
    "X_testing_data_reshaped = np.array(X_testing_data).reshape(-1,X_threshold_scaled_data.shape[1])\n",
    "\n",
    "#Create model instance and determine layers, neurals and activation features\n",
    "model = Sequential([\n",
    "    Dense(350,activation='relu', input_shape=(X_threshold_scaled_data.shape[1],)),\n",
    "    Dense(250, activation='relu'),\n",
    "    Dense(150, activation='relu'),\n",
    "    Dense(4, activation='softmax')])\n",
    "#determine metrics, loss function and compiler\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#fit model\n",
    "model_history = model.fit(X_threshold_scaled_data_reshaped, np.array(Y_nn).reshape(-1,), batch_size=100, epochs=4, validation_split=0.1)\n",
    "#predict y variable for test data\n",
    "y_pred = model.predict(X_testing_data_reshaped)\n",
    "\n",
    "result_testing = testing_data.copy()\n",
    "print('done')\n",
    "#add all y predictions to result dataframe\n",
    "result_testing['sentiment'] = [x for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print y prediction shape\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display result dataframe information\n",
    "result_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to change scientific values to float\n",
    "def change(list_num):\n",
    "    empty = []\n",
    "    for x in list_num:\n",
    "        empty.append(round(float(x),4))\n",
    "    return empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply change function on y predictions\n",
    "result_testing['sentiment'] = result_testing['sentiment'].apply(change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the location of max probability class and return correct response variable\n",
    "def locate_max(number_list):\n",
    "    location_list = number_list.index(max(number_list))\n",
    "    return location_list -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply locate max function on sentiment\n",
    "result_testing['sentiment'] = result_testing['sentiment'].apply(locate_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display sentiment data\n",
    "result_testing['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show sentiment count per class\n",
    "result_testing['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export results to csv for submission\n",
    "result_testing = result_testing[['tweetid','sentiment']]\n",
    "result_testing.to_csv('NNC_clf.csv', index=False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save model used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use file format h5 and store structured data\n",
    "file = 'model.h5'\n",
    "#save model\n",
    "model.save(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import load_model library\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved classification model\n",
    "loaded_classification_model = load_model(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test prediction of y\n",
    "y_pred = model.predict(X_testing_data_reshaped)\n",
    "#create copy of test data\n",
    "result_testing = testing_data.copy()\n",
    "\n",
    "#add all y predictions to result dataframe\n",
    "result_testing['sentiment'] = [x for x in y_pred]\n",
    "#create function to change scientific values to float\n",
    "def change(list_num):\n",
    "    empty = []\n",
    "    for x in list_num:\n",
    "        empty.append(round(float(x),4))\n",
    "    return empty\n",
    "#apply change function on y predictions\n",
    "result_testing['sentiment'] = result_testing['sentiment'].apply(change)\n",
    "#display the location of max probability class and return correct response variable\n",
    "def locate_max(number_list):\n",
    "    location_list = number_list.index(max(number_list))\n",
    "    return location_list -1\n",
    "#display sentiment data\n",
    "result_testing['sentiment'] = result_testing['sentiment'].apply(locate_max)\n",
    "result_testing['sentiment']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
